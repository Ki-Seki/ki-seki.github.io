---
math: true
---

### Classifier-Free Guidance

{{% admonition type="quote" title="Classifier-Free Guidance é‡‡æ ·å…¬å¼" open=true %}}
$$
\begin{aligned}
\nabla_{\mathbf{x}_t} \log p(y \vert \mathbf{x}_t)
&= \nabla_{\mathbf{x}_t} \log p(\mathbf{x}_t \vert y) - \nabla_{\mathbf{x}_t} \log p(\mathbf{x}_t) \\
&= - \frac{1}{\sqrt{1 - \bar{\alpha}_t}}\Big( \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, y) - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \Big) \\
\bar{\boldsymbol{\epsilon}}_\theta(\mathbf{x}_t, t, y)
&= \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, y) - \sqrt{1 - \bar{\alpha}_t} \; w \nabla_{\mathbf{x}_t} \log p(y \vert \mathbf{x}_t) \\
&= \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, y) + w \big(\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, y) - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \big) \\
&= (w+1) \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, y) - w \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)
\end{aligned}
$$
{{% /admonition %}}

classifer guided diffusion åˆ©ç”¨ä¸¤ä¸ªå·²ç»è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œæ— éœ€å…¶ä»–æ“ä½œï¼Œè¿™ä¸ªä¼˜åŠ¿å¾ˆæ˜æ˜¾ã€‚ä½†å¦å¤–ä¸€ä¸ªä¼˜åŠ¿æ˜¯ï¼Œå¯ä»¥æ§åˆ¶â€œconditioinâ€çš„å¼ºåº¦ï¼Œé€šè¿‡å‰é¢æåˆ°çš„$w$ æƒé‡ã€‚

è€Œå¯¹äº claasifer-free guidanceï¼Œæœ€ç®€å•çš„å°±æ˜¯ç›´æ¥æŠŠconditionä¿¡æ¯è®­ç»ƒè¿›diffusionæ¨¡å‹å³å¯ï¼Œä½†æ˜¯å°±å¤±å»conditionå¼ºåº¦æ§åˆ¶çš„å¼ºåº¦è¿™ä¸ªfeatureäº†ã€‚

é‚£å¦å¤–ä¸€ç§æ€è·¯æ˜¯ï¼Œå¦‚åŸåšæ–‡æ‰€ç¤ºï¼Œå’Œå¸¦æœ‰pre-trained classifer-based condition generationä¸åŒçš„æ˜¯ï¼Œclassifier-free guidanceéœ€è¦ä¸€ä¸ªpre-trained unconditioned diffusionï¼Œä»¥åŠä¸€ä¸ªç”±$(\mathbf{x}_t, y)$ pairs é¢å¤–è®­ç»ƒçš„ conditiondiffusionæ¨¡å‹ï¼Œé€šè¿‡ä¸¤è€…çš„â€œç›¸å‡â€æ¥æ„å»ºå‡ºconditional diffusion modelã€‚

ğŸ§  Classifier-Free Guidance å…¨é¢æ€»ç»“

1ï¸âƒ£ èƒŒæ™¯ä¸åŠ¨æœº

ä¼ ç»Ÿçš„æ‰©æ•£æ¨¡å‹å¼•å¯¼æ–¹æ³•ï¼ˆå¦‚ Classifier Guidanceï¼‰ä¾èµ–ä¸€ä¸ªé¢å¤–çš„åˆ†ç±»å™¨ \( f_\phi(y|x_t) \)ï¼Œé€šè¿‡å…¶æ¢¯åº¦æ¥å¼•å¯¼ç”Ÿæˆè¿‡ç¨‹ã€‚ä½†è¿™ç§æ–¹æ³•å­˜åœ¨ï¼š

- åˆ†ç±»å™¨å®¹æ˜“è¢« adversarial prompt è¯¯å¯¼ï¼›
- å¢åŠ è®­ç»ƒå’Œæ¨ç†å¤æ‚åº¦ï¼›
- éœ€è¦é¢å¤–æ¨¡å‹å‚æ•°ã€‚

**Classifier-Free Guidance** æä¾›äº†ä¸€ç§æ— éœ€ç‹¬ç«‹åˆ†ç±»å™¨çš„æ›¿ä»£æ–¹æ¡ˆã€‚

---

2ï¸âƒ£ æ ¸å¿ƒæ€æƒ³

ä½¿ç”¨ä¸€ä¸ªç»Ÿä¸€çš„æ¨¡å‹ \( \epsilon_\theta(x_t, t, y) \)ï¼Œé€šè¿‡è®­ç»ƒæ—¶éšæœºä¸¢å¼ƒæ¡ä»¶ \( y \)ï¼Œè®©æ¨¡å‹åŒæ—¶å­¦ä¼šï¼š

- æœ‰æ¡ä»¶ç”Ÿæˆï¼šè¾“å…¥ \( y \)
- æ— æ¡ä»¶ç”Ÿæˆï¼šè¾“å…¥ \( y = \emptyset \)

ç„¶ååœ¨æ¨ç†æ—¶é€šè¿‡ä¸¤ç§ score çš„å·®å€¼æ¥æ¨¡æ‹Ÿåˆ†ç±»å™¨æ¢¯åº¦ï¼š

\[
\nabla_{x_t} \log p(y | x_t) = \nabla_{x_t} \log p(x_t | y) - \nabla_{x_t} \log p(x_t)
\]

è¿‘ä¼¼ä¸ºï¼š

\[
\nabla_{x_t} \log p(y | x_t) \approx -\frac{1}{1 - \bar{\alpha}_t} \left( \epsilon_\theta(x_t, t, y) - \epsilon_\theta(x_t, t) \right)
\]

æœ€ç»ˆæ„é€ å¼•å¯¼åçš„ scoreï¼š

\[
\bar{\epsilon}_\theta(x_t, t, y) = (1 + w) \cdot \epsilon_\theta(x_t, t, y) - w \cdot \epsilon_\theta(x_t, t)
\]

å…¶ä¸­ \( w \) æ˜¯å¼•å¯¼å¼ºåº¦ã€‚

---

3ï¸âƒ£ è´å¶æ–¯å…¬å¼æ¨å¯¼ç»†èŠ‚

ä½ æŒ‡å‡ºçš„éå¸¸å…³é”®çš„ä¸€ç‚¹ï¼š

\[
\log p(y | x_t) = \log p(x_t | y) + \log p(y) - \log p(x_t)
\]

å¯¹ \( x_t \) æ±‚å¯¼åï¼š

\[
\nabla_{x_t} \log p(y | x_t) = \nabla_{x_t} \log p(x_t | y) - \nabla_{x_t} \log p(x_t)
\]

å…¶ä¸­ \( \nabla_{x_t} \log p(y) = 0 \)ï¼Œå› ä¸º \( y \) ä¸ \( x_t \) æ— å…³ï¼Œæ˜¯å¸¸æ•°é¡¹ã€‚å› æ­¤åŸæ–‡çš„æ¨å¯¼æ˜¯åˆç†çš„ã€‚

---

4ï¸âƒ£ æ¨¡å‹ç»“æ„ä¸å‚æ•°å…±äº«

- âœ… åªä½¿ç”¨ä¸€ä¸ªæ¨¡å‹ï¼ˆä¸€ä¸ªå‚æ•°é›†ï¼‰
- âœ… æ¡ä»¶ä¿¡æ¯ \( y \) é€šè¿‡è¾“å…¥æ§åˆ¶æ˜¯å¦å­˜åœ¨
- âœ… æ— éœ€ä¿ç•™ä¸¤å¥—å‚æ•°
- âœ… èŠ‚çœè®¡ç®—èµ„æºï¼Œç®€åŒ–éƒ¨ç½²

è®­ç»ƒæ—¶çš„ç­–ç•¥ï¼š

- æ¯ä¸ª batch ä¸­ï¼Œä»¥ä¸€å®šæ¦‚ç‡å°† \( y \) æ›¿æ¢ä¸ºç‰¹æ®Š tokenï¼ˆå¦‚ç©ºå­—ç¬¦ä¸²æˆ–å…¨é›¶å‘é‡ï¼‰
- æ¨¡å‹å­¦ä¼šåœ¨ \( y \) å­˜åœ¨ä¸ç¼ºå¤±ä¸¤ç§æƒ…å†µä¸‹éƒ½èƒ½é¢„æµ‹å™ªå£°

---

5ï¸âƒ£ æ¡ä»¶è¾“å…¥çš„å¤„ç†æ–¹å¼

- \( y = \emptyset \) å¹¶ä¸æ˜¯â€œéšä¾¿è¾“å…¥ç‚¹å†…å®¹â€ï¼Œè€Œæ˜¯æ˜ç¡®è¾“å…¥ä¸€ä¸ªâ€œç©ºæ¡ä»¶â€æ ‡è®°ï¼›
- åœ¨æ–‡æœ¬ä»»åŠ¡ä¸­å¯ä»¥æ˜¯ç©ºå­—ç¬¦ä¸²ã€ç‰¹æ®Š tokenï¼›
- åœ¨å›¾åƒä»»åŠ¡ä¸­å¯ä»¥æ˜¯å…¨é›¶ embeddingï¼›
- æ¨¡å‹å†…éƒ¨ embedding å±‚ä¼šå¤„ç†è¿™ç§æƒ…å†µã€‚

---

 6ï¸âƒ£ æ¡ä»¶ç±»å‹çš„å¤šæ ·æ€§

ä½ é—®åˆ°æ˜¯å¦åªèƒ½è®­ç»ƒåœ¨ä¸€ç§ \( y \) ä¸Šï¼Œç­”æ¡ˆæ˜¯ï¼š

- âŒ ä¸é™äºä¸€ç§æ¡ä»¶ï¼›
- âœ… å¯ä»¥è®­ç»ƒåœ¨å¤šç§ç±»åˆ«æ ‡ç­¾ã€æ–‡æœ¬æè¿°ã€è¯­ä¹‰å›¾ç­‰ï¼›
- åªè¦è®­ç»ƒæ•°æ®è¦†ç›–å……åˆ†ï¼Œæ¨¡å‹å°±èƒ½å­¦ä¼šåœ¨æ•´ä¸ª \( p(y) \) åˆ†å¸ƒä¸Šè¿›è¡Œæ¡ä»¶ç”Ÿæˆã€‚

---

7ï¸âƒ£ å®éªŒéªŒè¯ä¸ä¼˜åŠ¿

- GLIDE æ¨¡å‹å¯¹æ¯”äº† CLIP Guidance ä¸ Classifier-Free Guidanceï¼›
- å‘ç°åè€…æ›´ç¨³å®šï¼Œå›¾åƒè´¨é‡ä¸è¯­ä¹‰ä¸€è‡´æ€§æ›´å¥½ï¼›
- åŸå› æ˜¯ CLIP Guidance å®¹æ˜“è¢« adversarial prompt è¯¯å¯¼ï¼Œè€Œ Classifier-Free Guidance æ˜¯ä»æ•°æ®åˆ†å¸ƒä¸­ç›´æ¥å»ºæ¨¡ã€‚

---

âœ… æ€»ç»“è¡¨æ ¼

| é¡¹ç›® | Classifier-Free Guidance |
|------|---------------------------|
| æ˜¯å¦éœ€è¦é¢å¤–åˆ†ç±»å™¨ | âŒ ä¸éœ€è¦ |
| å‚æ•°æ•°é‡ | âœ… ä¸€å¥—å…±äº«å‚æ•° |
| æ¡ä»¶è¾“å…¥å¤„ç† | âœ… éšæœºä¸¢å¼ƒæ¡ä»¶è®­ç»ƒ |
| æ˜¯å¦æ”¯æŒå¤šç§æ¡ä»¶ç±»å‹ | âœ… æ”¯æŒ |
| æ¨ç†æ—¶å¼•å¯¼æ–¹å¼ | âœ… æ¡ä»¶ä¸æ— æ¡ä»¶ score å·®å€¼ |
| è´å¶æ–¯å…¬å¼æ˜¯å¦å®Œæ•´ | âœ… å¿½ç•¥å¸¸æ•°é¡¹åæ˜¯åˆç†çš„ |
| å®éªŒæ•ˆæœ | âœ… FID ä¸ IS å¹³è¡¡è‰¯å¥½ |
| å®è·µæ¨¡å‹ | GLIDEã€Imagen ç­‰å‡é‡‡ç”¨ |

{{% admonition type="quote" title="Title" open=true %}}
Their experiments showed that classifier-free guidance can achieve a good balance between FID (distinguish between synthetic and generated images) and IS (quality and diversity).
{{% /admonition %}}

ğŸ“Š FIDï¼ˆFrÃ©chet Inception Distanceï¼‰ã€è®ºæ–‡ï¼šhttps://arxiv.org/abs/1706.08500ã€‘
âœ… å®šä¹‰ï¼š
FID è¡¡é‡çš„æ˜¯ç”Ÿæˆå›¾åƒä¸çœŸå®å›¾åƒåœ¨ç‰¹å¾ç©ºé—´ä¸­çš„åˆ†å¸ƒå·®å¼‚ã€‚å®ƒä½¿ç”¨ Inception ç½‘ç»œæå–å›¾åƒç‰¹å¾ï¼Œç„¶åè®¡ç®—ä¸¤ä¸ªé«˜ç»´é«˜æ–¯åˆ†å¸ƒä¹‹é—´çš„ FrÃ©chet è·ç¦»ã€‚

âœ… å…¬å¼ï¼š
\[
\text{FID} = \|\mu_r - \mu_g\|^2 + \text{Tr}(\Sigma_r + \Sigma_g - 2(\Sigma_r \Sigma_g)^{1/2})
\]
å…¶ä¸­ï¼š

- \( \mu_r, \Sigma_r \)ï¼šçœŸå®å›¾åƒçš„å‡å€¼å’Œåæ–¹å·®
- \( \mu_g, \Sigma_g \)ï¼šç”Ÿæˆå›¾åƒçš„å‡å€¼å’Œåæ–¹å·®
âœ… è§£è¯»ï¼š
- FID è¶Šä½ï¼Œè¡¨ç¤ºç”Ÿæˆå›¾åƒä¸çœŸå®å›¾åƒè¶Šæ¥è¿‘ï¼›
- æ—¢è€ƒè™‘å›¾åƒè´¨é‡ï¼Œä¹Ÿè€ƒè™‘åˆ†å¸ƒä¸€è‡´æ€§ï¼›
- å¯¹å›¾åƒæ¨¡ç³Šã€å¤±çœŸã€æ¨¡å¼å´©æºƒï¼ˆmode collapseï¼‰éƒ½å¾ˆæ•æ„Ÿã€‚

ğŸŒˆ ISï¼ˆInception Scoreï¼‰ã€è®ºæ–‡ï¼šhttps://arxiv.org/abs/1606.03498ã€‘

âœ… å®šä¹‰ï¼š
IS è¡¡é‡çš„æ˜¯ç”Ÿæˆå›¾åƒçš„â€œæ¸…æ™°åº¦â€å’Œâ€œå¤šæ ·æ€§â€ã€‚å®ƒä½¿ç”¨ Inception ç½‘ç»œé¢„æµ‹å›¾åƒç±»åˆ«åˆ†å¸ƒï¼Œç„¶åè®¡ç®—é¢„æµ‹åˆ†å¸ƒçš„ KL æ•£åº¦ã€‚

âœ… å…¬å¼ï¼š
\[
\text{IS} = \exp\left( \mathbb{E}_{x \sim p_g} \left[ D_{\text{KL}}(p(y|x) \| p(y)) \right] \right)
\]
å…¶ä¸­ï¼š

- \( p(y|x) \)ï¼šInception ç½‘ç»œå¯¹ç”Ÿæˆå›¾åƒçš„é¢„æµ‹åˆ†å¸ƒ
- \( p(y) \)ï¼šæ‰€æœ‰ç”Ÿæˆå›¾åƒçš„å¹³å‡é¢„æµ‹åˆ†å¸ƒ

 âœ… è§£è¯»ï¼š

- IS è¶Šé«˜ï¼Œè¡¨ç¤ºå›¾åƒæ¸…æ™°ï¼ˆé¢„æµ‹åˆ†å¸ƒç†µä½ï¼‰ä¸”å¤šæ ·æ€§é«˜ï¼ˆå¹³å‡åˆ†å¸ƒç†µé«˜ï¼‰ï¼›
- é€‚åˆè¯„ä¼°å›¾åƒçš„â€œè¯­ä¹‰æ¸…æ™°åº¦â€å’Œâ€œç±»åˆ«è¦†ç›–åº¦â€ï¼›
- å¯¹å›¾åƒæ¨¡ç³Šæˆ–é‡å¤ç”ŸæˆåŒä¸€ç±»åˆ«éå¸¸æ•æ„Ÿã€‚

ğŸ§ª åœ¨ Classifier-Free Guidance ä¸­çš„ä½œç”¨

- å®éªŒè¡¨æ˜ï¼Œ**é€‚å½“çš„ guidance scale \( w \)** å¯ä»¥åœ¨ FID å’Œ IS ä¹‹é—´å–å¾—è‰¯å¥½å¹³è¡¡ï¼›
- å¤ªå°çš„ \( w \)ï¼šå›¾åƒå¤šæ ·æ€§é«˜ä½†è´¨é‡å·®ï¼ˆFID é«˜ï¼ŒIS ä½ï¼‰ï¼›
- å¤ªå¤§çš„ \( w \)ï¼šå›¾åƒè´¨é‡é«˜ä½†å®¹æ˜“æ¨¡å¼å´©æºƒï¼ˆFID ä½ï¼ŒIS ä¸‹é™ï¼‰ï¼›
- æ‰€ä»¥ Classifier-Free Guidance çš„ä¼˜åŠ¿ä¹‹ä¸€å°±æ˜¯å¯ä»¥**çµæ´»è°ƒèŠ‚ \( w \)** æ¥æ§åˆ¶è¿™ä¸ª trade-offã€‚

{{% admonition type="quote" title="Title" open=true %}}
The guided diffusion model, GLIDE ([Nichol, Dhariwal & Ramesh, et al. 2022](https://arxiv.org/abs/2112.10741)), explored both guiding strategies, CLIP guidance and classifier-free guidance, and found that the latter is more preferred. They hypothesized that it is because CLIP guidance exploits the model with adversarial examples towards the CLIP model, rather than optimize the better matched images generation.
{{% /admonition %}}

GLIDE æ˜¯ä¸€ç§å¼•å¯¼å¼æ‰©æ•£æ¨¡å‹ï¼ˆguided diffusion modelï¼‰ï¼Œç”± Nicholã€Dhariwal å’Œ Ramesh ç­‰äººåœ¨ 2022 å¹´æå‡ºã€‚å®ƒå°è¯•äº†ä¸¤ç§å›¾åƒç”Ÿæˆçš„å¼•å¯¼ç­–ç•¥ï¼š

1. **CLIP guidanceï¼ˆCLIP å¼•å¯¼ï¼‰**ï¼šåˆ©ç”¨ CLIP æ¨¡å‹çš„å›¾æ–‡åŒ¹é…èƒ½åŠ›æ¥å¼•å¯¼å›¾åƒç”Ÿæˆè¿‡ç¨‹ã€‚
2. **Classifier-free guidanceï¼ˆæ— åˆ†ç±»å™¨å¼•å¯¼ï¼‰**ï¼šä¸ä¾èµ–å¤–éƒ¨åˆ†ç±»å™¨ï¼Œè€Œæ˜¯é€šè¿‡è®­ç»ƒä¸€ä¸ªæ¨¡å‹åŒæ—¶å­¦ä¹ æœ‰æ¡ä»¶å’Œæ— æ¡ä»¶çš„å›¾åƒç”Ÿæˆï¼Œä»è€Œå®ç°å¼•å¯¼ã€‚

GLIDE çš„å®éªŒå‘ç°ï¼Œ**æ— åˆ†ç±»å™¨å¼•å¯¼æ¯” CLIP å¼•å¯¼æ›´å—æ¬¢è¿**ã€‚ä»–ä»¬çš„è§£é‡Šæ˜¯ï¼šCLIP å¼•å¯¼å¯èƒ½ä¼šè®©ç”Ÿæˆæ¨¡å‹â€œè¿‡åº¦è¿åˆâ€CLIP æ¨¡å‹çš„åˆ¤æ–­æ ‡å‡†ï¼Œç”šè‡³ç”Ÿæˆä¸€äº›å¯¹ CLIP æ¨¡å‹â€œçœ‹èµ·æ¥å¾ˆå¥½â€ä½†å®é™…ä¸Šå¹¶ä¸çœŸå®æˆ–åˆç†çš„å›¾åƒï¼ˆè¿™ç±»å›¾åƒå¯ä»¥è¢«è§†ä¸ºå¯¹ CLIP çš„â€œå¯¹æŠ—æ ·æœ¬â€ï¼‰ã€‚æ¢å¥è¯è¯´ï¼ŒCLIP guidance æ›´åƒæ˜¯åœ¨â€œè®¨å¥½â€CLIP æ¨¡å‹ï¼Œè€Œä¸æ˜¯åœ¨çœŸæ­£ä¼˜åŒ–å›¾åƒä¸æ–‡æœ¬ä¹‹é—´çš„åŒ¹é…è´¨é‡ã€‚

ğŸ” ç®€åŒ–ç†è§£ï¼š

- æ— åˆ†ç±»å™¨å¼•å¯¼ï¼šæ¨¡å‹è‡ªå·±å­¦ä¼šæ€ä¹ˆç”Ÿæˆå›¾åƒï¼Œä¸ä¾èµ–å¤–éƒ¨åˆ¤æ–­ã€‚
- CLIP å¼•å¯¼ï¼šæ¨¡å‹ä¾èµ– CLIP çš„è¯„åˆ†ï¼Œä½†å¯èƒ½ä¼šâ€œä½œå¼Šâ€å»éª—è¿‡ CLIPã€‚
- GLIDE æ›´åå¥½å‰è€…ï¼Œå› ä¸ºå®ƒæ›´è‡ªç„¶ã€æ›´ç¨³å¥ã€‚

## Speed up Diffusion Models

### Fewer Sampling Steps & Distillation

{{% admonition type="quote" title="Title" open=true %}}
One simple way is to run a strided sampling schedule (Nichol & Dhariwal, 2021) by taking the sampling update every $\lceil T/S \rceil$ steps to reduce the process from $T$ to $S$ steps. The new sampling schedule for generation is $\{\tau_1, \dots, \tau_S\}$ where $\tau_1 < \tau_2 < \dots <\tau_S \in [1, T]$ and $S < T$.
{{% /admonition %}}

PSã€‚ä¸€å®šè®°å¾—ï¼Œåªè¦æåˆ°samplingï¼Œå°±æ˜¯æŒ‡å°†è®­ç»ƒå¥½çš„æ¨¡å‹ç”¨äºæ¨ç†ï¼Œæœ¬èŠ‚ Speed up Diffusion Models è®²çš„ä¹Ÿéƒ½æ˜¯å¦‚ä½•åŠ é€Ÿæ¨¡å‹reasoningã€‚

è¿™é‡Œè¯´çš„å¾ˆç®€ç•¥ï¼Œåªæ˜¯è¯´ç”¨ä¸ªæ–°çš„å­åºåˆ—ï¼Œæ²¡æœ‰è®²å…·ä½“æ€ä¹ˆsampleï¼Œä¸‹é¢æ˜¯ç›¸å…³æ¨å¯¼ï¼š

éå¸¸æ£’çš„é—®é¢˜ï¼æˆ‘ä»¬æ¥ç³»ç»Ÿæ¨å¯¼ä¸€ä¸‹åœ¨ä½¿ç”¨å­åºåˆ— \( S = \{S_1, S_2, \dots, S_K\} \) è¿›è¡ŒåŠ é€Ÿé‡‡æ ·æ—¶ï¼Œå¦‚ä½•é‡å®šä¹‰æ‰©æ•£æ¨¡å‹ä¸­çš„å…³é”®å‚æ•°ï¼Œå°¤å…¶æ˜¯ï¼š

- ç´¯ç§¯å™ªå£°å› å­ \( \bar{\alpha}_{S_t} \)
- åå‘é‡‡æ ·çš„æ–¹å·® \( \tilde{\beta}_{S_t} \)
- å‡å€¼é¡¹ \( \mu_{S_t} \)

---

ğŸ§® 1. ä»å®Œæ•´æ‰©æ•£è¿‡ç¨‹å‡ºå‘

åœ¨æ ‡å‡† DDPM ä¸­ï¼Œæ­£å‘è¿‡ç¨‹å®šä¹‰ä¸ºï¼š

\[
q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{\alpha_t} x_{t-1}, (1 - \alpha_t) \mathbf{I})
\]

å…¶ä¸­ï¼š

- \( \alpha_t = 1 - \beta_t \)
- \( \bar{\alpha}_t = \prod_{i=1}^t \alpha_i \)

ç”±æ­¤å¯ä»¥å¾—åˆ°ï¼š

\[
q(x_t | x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) \mathbf{I})
\]

---

ğŸ§­ 2. å­åºåˆ—é‡‡æ ·çš„ç›®æ ‡

æˆ‘ä»¬å¸Œæœ›ä» \( x_{S_t} \) ç›´æ¥é‡‡æ ·åˆ° \( x_{S_{t-1}} \)ï¼Œè·³è¿‡ä¸­é—´çš„æ—¶é—´æ­¥ã€‚ç”±äºæ‰©æ•£è¿‡ç¨‹æ˜¯é©¬å°”ç§‘å¤«é“¾ï¼Œæˆ‘ä»¬å¯ä»¥æ„é€ å¦‚ä¸‹çš„åéªŒåˆ†å¸ƒï¼š

\[
q(x_{S_{t-1}} | x_{S_t}, x_0) = \mathcal{N}(x_{S_{t-1}}; \mu_{S_t}, \tilde{\beta}_{S_t} \mathbf{I})
\]

ğŸ§  3. æ¨å¯¼å‡å€¼é¡¹ \( \mu_{S_t} \)

æ ¹æ® Bayes è§„åˆ™å’Œé«˜æ–¯åˆå¹¶å…¬å¼ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ï¼š

\[
\mu_{S_t} = \frac{\sqrt{\alpha_{S_t}} (1 - \bar{\alpha}_{S_{t-1}})}{1 - \bar{\alpha}_{S_t}} x_{S_t} + \frac{\sqrt{\bar{\alpha}_{S_{t-1}}} (1 - \alpha_{S_t})}{1 - \bar{\alpha}_{S_t}} x_0
\]

è¿™ä¸ªå…¬å¼çš„æ¨å¯¼æ ¸å¿ƒåœ¨äºå°†ä¸¤ä¸ªé«˜æ–¯åˆ†å¸ƒï¼š

- \( q(x_{S_t} | x_{S_{t-1}}) \)
- \( q(x_{S_{t-1}} | x_0) \)

åˆå¹¶ä¸ºä¸€ä¸ªæ¡ä»¶åˆ†å¸ƒ \( q(x_{S_{t-1}} | x_{S_t}, x_0) \)ï¼Œå¹¶åˆ©ç”¨é«˜æ–¯ä¹˜ç§¯å…¬å¼å®Œæˆæ¨å¯¼ã€‚

ğŸ“‰ 4. æ¨å¯¼æ–¹å·®é¡¹ \( \tilde{\beta}_{S_t} \)

åŒæ ·åœ°ï¼ŒåéªŒæ–¹å·®å¯ä»¥æ¨å¯¼ä¸ºï¼š

\[
\tilde{\beta}_{S_t} = \frac{(1 - \alpha_{S_t})(1 - \bar{\alpha}_{S_{t-1}})}{1 - \bar{\alpha}_{S_t}}
\]

è¿™ä¸ªè¡¨è¾¾å¼ç¡®ä¿æˆ‘ä»¬åœ¨è·³è·ƒé‡‡æ ·æ—¶ä»ç„¶ä¿æŒæ­£ç¡®çš„å™ªå£°æ¯”ä¾‹ã€‚

ğŸ§ª 5. å¦‚æœç”¨ DDIMï¼ˆç¡®å®šæ€§é‡‡æ ·ï¼‰

DDIM ä¼šå°†é‡‡æ ·è¿‡ç¨‹æ”¹å†™ä¸ºï¼š

\[
x_{S_{t-1}} = \sqrt{\bar{\alpha}_{S_{t-1}}} x_0 + \sqrt{1 - \bar{\alpha}_{S_{t-1}}} \cdot \epsilon
\]

å…¶ä¸­ \( x_0 \) æ˜¯ç”±æ¨¡å‹é¢„æµ‹çš„ï¼Œé€šå¸¸é€šè¿‡ï¼š

\[
x_0 = \frac{x_{S_t} - \sqrt{1 - \bar{\alpha}_{S_t}} \cdot \epsilon_\theta(x_{S_t}, S_t)}{\sqrt{\bar{\alpha}_{S_t}}}
\]

ç„¶åä»£å…¥ä¸Šå¼å³å¯å®Œæˆä¸€æ­¥è·³è·ƒé‡‡æ ·ã€‚

âœ… æ€»ç»“è¡¨æ ¼

| å‚æ•° | å®šä¹‰ | ä½œç”¨ |
|------|------|------|
| \( \bar{\alpha}_{S_t} \) | \( \prod_{i=1}^{S_t} \alpha_i \) | ç´¯ç§¯å™ªå£°å› å­ |
| \( \mu_{S_t} \) | è§ä¸Šå¼ | åéªŒå‡å€¼ï¼Œç”¨äºé‡‡æ · |
| \( \tilde{\beta}_{S_t} \) | è§ä¸Šå¼ | åéªŒæ–¹å·®ï¼Œç”¨äºé‡‡æ · |
| \( x_0 \) | ç”±æ¨¡å‹é¢„æµ‹ | ç”¨äºæ„é€ é‡‡æ ·åˆ†å¸ƒ |

{{% admonition type="quote" title="Title" open=true %}}
$$
\begin{aligned}
\mathbf{x}_{t-1} 
&= \sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0 +  \sqrt{1 - \bar{\alpha}_{t-1}}\boldsymbol{\epsilon}_{t-1} & \\
&= \sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_{t-1} - \sigma_t^2} \boldsymbol{\epsilon}_t + \sigma_t\boldsymbol{\epsilon} & \\
&= \sqrt{\bar{\alpha}_{t-1}} \Big( \frac{\mathbf{x}_t - \sqrt{1 - \bar{\alpha}_t} \epsilon^{(t)}_\theta(\mathbf{x}_t)}{\sqrt{\bar{\alpha}_t}} \Big) + \sqrt{1 - \bar{\alpha}_{t-1} - \sigma_t^2} \epsilon^{(t)}_\theta(\mathbf{x}_t) + \sigma_t\boldsymbol{\epsilon} \\
q_\sigma(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)
&= \mathcal{N}(\mathbf{x}_{t-1}; \sqrt{\bar{\alpha}_{t-1}} \Big( \frac{\mathbf{x}_t - \sqrt{1 - \bar{\alpha}_t} \epsilon^{(t)}_\theta(\mathbf{x}_t)}{\sqrt{\bar{\alpha}_t}} \Big) + \sqrt{1 - \bar{\alpha}_{t-1} - \sigma_t^2} \epsilon^{(t)}_\theta(\mathbf{x}_t), \sigma_t^2 \mathbf{I})
\end{aligned}
$$
{{% /admonition %}}

è¿™ä¸ªå˜æ¢çš„å…³é”®åœ¨äºç†è§£æ‰©æ•£æ¨¡å‹ä¸­çš„**åå‘è¿‡ç¨‹è¿‘ä¼¼**ï¼Œç‰¹åˆ«æ˜¯å¦‚ä½•å°† $\mathbf{x}_0$ å’Œ $\boldsymbol{\epsilon}_{t-1}$ è¡¨è¾¾ä¸ºå…³äº $\mathbf{x}_t$ å’Œé¢„æµ‹å™ªå£° $\epsilon_\theta^{(t)}(\mathbf{x}_t)$ çš„å‡½æ•°ã€‚æˆ‘ä»¬æ¥é€æ­¥æ‹†è§£ç¬¬äºŒæ­¥çš„å˜æ¢ï¼š

ğŸ§© ç¬¬ä¸€æ­¥ï¼šåŸå§‹å½¢å¼

\[
\mathbf{x}_{t-1} = \sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_{t-1}}\boldsymbol{\epsilon}_{t-1}
\]

è¿™æ˜¯æ ‡å‡†çš„å‰å‘è¿‡ç¨‹é‡‡æ ·å…¬å¼ï¼Œè¡¨ç¤ºä» $\mathbf{x}_0$ ç”Ÿæˆ $\mathbf{x}_{t-1}$ çš„æ–¹å¼ã€‚

ğŸ”„ ç¬¬äºŒæ­¥ï¼šå¼•å…¥ä¸¤ä¸ªå™ªå£°é¡¹çš„åˆ†è§£

\[
\boldsymbol{\epsilon}_{t-1} = \sqrt{\frac{1 - \bar{\alpha}_{t-1} - \sigma_t^2}{1 - \bar{\alpha}_{t-1}}} \boldsymbol{\epsilon}_t + \sqrt{\frac{\sigma_t^2}{1 - \bar{\alpha}_{t-1}}} \boldsymbol{\epsilon}
\]

è¿™æ˜¯ä¸€ä¸ª**é‡æ–°å‚æ•°åŒ–æŠ€å·§**ï¼Œå°†åŸå§‹çš„é«˜æ–¯å™ªå£° $\boldsymbol{\epsilon}_{t-1}$ åˆ†è§£ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼š

- ä¸€ä¸ªæ˜¯ä¸æ—¶é—´æ­¥ $t$ çš„å™ªå£° $\boldsymbol{\epsilon}_t$ ç›¸å…³çš„éƒ¨åˆ†ï¼›
- ä¸€ä¸ªæ˜¯ç‹¬ç«‹çš„é«˜æ–¯å™ªå£° $\boldsymbol{\epsilon} \sim \mathcal{N}(0, \mathbf{I})$ï¼Œç”¨äºæ§åˆ¶é‡‡æ ·çš„æ–¹å·® $\sigma_t^2$ã€‚

ä»£å…¥åå¾—åˆ°ï¼š

\[
\mathbf{x}_{t-1} = \sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_{t-1} - \sigma_t^2} \boldsymbol{\epsilon}_t + \sigma_t\boldsymbol{\epsilon}
\]

ğŸ” ç¬¬ä¸‰æ­¥ï¼šå°† $\mathbf{x}_0$ è¡¨è¾¾ä¸º $\mathbf{x}_t$ å’Œé¢„æµ‹å™ªå£°çš„å‡½æ•°

åˆ©ç”¨å‰å‘è¿‡ç¨‹çš„å…¬å¼ï¼š

\[
\mathbf{x}_t = \sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t} \boldsymbol{\epsilon}_t
\quad \Rightarrow \quad
\mathbf{x}_0 = \frac{\mathbf{x}_t - \sqrt{1 - \bar{\alpha}_t} \boldsymbol{\epsilon}_t}{\sqrt{\bar{\alpha}_t}}
\]

åœ¨è®­ç»ƒæ—¶ï¼Œæˆ‘ä»¬ç”¨æ¨¡å‹é¢„æµ‹çš„å™ªå£° $\epsilon_\theta^{(t)}(\mathbf{x}_t)$ æ¥è¿‘ä¼¼çœŸå®å™ªå£° $\boldsymbol{\epsilon}_t$ï¼Œäºæ˜¯ï¼š

\[
\mathbf{x}_0 \approx \frac{\mathbf{x}_t - \sqrt{1 - \bar{\alpha}_t} \epsilon_\theta^{(t)}(\mathbf{x}_t)}{\sqrt{\bar{\alpha}_t}}
\]

å°†è¿™ä¸ªè¡¨è¾¾å¼ä»£å…¥ä¸Šä¸€æ­¥çš„ $\mathbf{x}_{t-1}$ ä¸­ï¼Œå°±å¾—åˆ°äº†ç¬¬ä¸‰è¡Œçš„å½¢å¼ã€‚

ğŸ“Œ æ€»ç»“

ç¬¬äºŒæ­¥çš„å˜æ¢æ˜¯é€šè¿‡ä»¥ä¸‹ä¸¤ä¸ªå…³é”®æ“ä½œå®ç°çš„ï¼š

1. **é‡æ–°å‚æ•°åŒ–å™ªå£°é¡¹**ï¼šå°† $\boldsymbol{\epsilon}_{t-1}$ æ‹†æˆ $\boldsymbol{\epsilon}_t$ å’Œç‹¬ç«‹å™ªå£° $\boldsymbol{\epsilon}$ï¼›
2. **ç”¨æ¨¡å‹é¢„æµ‹çš„å™ªå£°è¿‘ä¼¼çœŸå®å™ªå£°**ï¼Œå¹¶å°† $\mathbf{x}_0$ è¡¨è¾¾ä¸º $\mathbf{x}_t$ å’Œ $\epsilon_\theta^{(t)}(\mathbf{x}_t)$ çš„å‡½æ•°ã€‚

è¿™ä¸€æ­¥æ˜¯æ„é€ åå‘è¿‡ç¨‹åˆ†å¸ƒ $q_\sigma(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)$ çš„æ ¸å¿ƒï¼Œä½¿å…¶å¯ä»¥ç”¨æ¨¡å‹é¢„æµ‹çš„å™ªå£°æ¥è¿›è¡Œé‡‡æ ·ã€‚


> å…³äºä¸ºä»€ä¹ˆé‚£ä¹ˆåˆ†è§£

è¿™ä¸ªåˆ†è§£å…¶å®æ˜¯ä¸€ä¸ª**é«˜æ–¯å™ªå£°çš„çº¿æ€§ç»„åˆæŠ€å·§**ï¼Œç›®çš„æ˜¯æ„é€ ä¸€ä¸ªæ–°çš„é«˜æ–¯å˜é‡ $\boldsymbol{\epsilon}_{t-1}$ï¼Œå®ƒä»ç„¶æ˜¯æ ‡å‡†æ­£æ€åˆ†å¸ƒï¼Œä½†ç”±ä¸¤ä¸ªç‹¬ç«‹çš„é«˜æ–¯å˜é‡ $\boldsymbol{\epsilon}_t$ å’Œ $\boldsymbol{\epsilon}$ ç»„åˆè€Œæˆã€‚æˆ‘ä»¬æ¥ä¸€æ­¥æ­¥æ‹†è§£è¿™ä¸ªåˆ†è§£çš„é€»è¾‘ï¼š

ğŸ¯ ç›®æ ‡ï¼šæ„é€ ä¸€ä¸ªæ–°çš„é«˜æ–¯å˜é‡

æˆ‘ä»¬å¸Œæœ›æ„é€ ä¸€ä¸ªå˜é‡ï¼š

\[
\boldsymbol{\epsilon}_{t-1} = a \boldsymbol{\epsilon}_t + b \boldsymbol{\epsilon}
\]

å…¶ä¸­ï¼š
- $\boldsymbol{\epsilon}_t \sim \mathcal{N}(0, \mathbf{I})$
- $\boldsymbol{\epsilon} \sim \mathcal{N}(0, \mathbf{I})$
- $\boldsymbol{\epsilon}_t$ å’Œ $\boldsymbol{\epsilon}$ æ˜¯**ç‹¬ç«‹çš„**

æˆ‘ä»¬å¸Œæœ›è¿™ä¸ªç»„åˆä»ç„¶æ»¡è¶³ï¼š

\[
\boldsymbol{\epsilon}_{t-1} \sim \mathcal{N}(0, \mathbf{I})
\]

ğŸ§® æ¡ä»¶ï¼šä¿æŒæ–¹å·®ä¸º 1

ç”±äº $\boldsymbol{\epsilon}_t$ å’Œ $\boldsymbol{\epsilon}$ ç‹¬ç«‹ï¼Œçº¿æ€§ç»„åˆçš„æ–¹å·®ä¸ºï¼š

\[
\text{Var}(\boldsymbol{\epsilon}_{t-1}) = a^2 \cdot \text{Var}(\boldsymbol{\epsilon}_t) + b^2 \cdot \text{Var}(\boldsymbol{\epsilon}) = a^2 + b^2
\]

ä¸ºäº†è®© $\boldsymbol{\epsilon}_{t-1} \sim \mathcal{N}(0, \mathbf{I})$ï¼Œæˆ‘ä»¬éœ€è¦ï¼š

\[
a^2 + b^2 = 1
\]

ğŸ§  ç°åœ¨å›åˆ°ä½ çš„å…¬å¼ï¼š

\[
\boldsymbol{\epsilon}_{t-1} = \sqrt{\frac{1 - \bar{\alpha}_{t-1} - \sigma_t^2}{1 - \bar{\alpha}_{t-1}}} \boldsymbol{\epsilon}_t + \sqrt{\frac{\sigma_t^2}{1 - \bar{\alpha}_{t-1}}} \boldsymbol{\epsilon}
\]

æˆ‘ä»¬å¯ä»¥è®¾ï¼š

- $a = \sqrt{\frac{1 - \bar{\alpha}_{t-1} - \sigma_t^2}{1 - \bar{\alpha}_{t-1}}}$
- $b = \sqrt{\frac{\sigma_t^2}{1 - \bar{\alpha}_{t-1}}}$

éªŒè¯ä¸€ä¸‹ï¼š

\[
a^2 + b^2 = \frac{1 - \bar{\alpha}_{t-1} - \sigma_t^2 + \sigma_t^2}{1 - \bar{\alpha}_{t-1}} = \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_{t-1}} = 1
\]

âœ… æ‰€ä»¥è¿™ä¸ªåˆ†è§£æ˜¯åˆæ³•çš„ï¼Œç¡®ä¿ $\boldsymbol{\epsilon}_{t-1}$ ä»ç„¶æ˜¯æ ‡å‡†æ­£æ€åˆ†å¸ƒã€‚

---

ğŸ” ä¸ºä»€ä¹ˆè¦è¿™ä¹ˆåˆ†è§£ï¼Ÿ

å› ä¸ºæˆ‘ä»¬å¸Œæœ›æ„é€ ä¸€ä¸ª**å¯æ§çš„é‡‡æ ·è¿‡ç¨‹**ï¼Œå…¶ä¸­ï¼š

- $\boldsymbol{\epsilon}_t$ æ˜¯æ¨¡å‹é¢„æµ‹çš„å™ªå£°ï¼ˆå¯è¢«ä¼°è®¡ï¼‰
- $\boldsymbol{\epsilon}$ æ˜¯éšæœºé‡‡æ ·çš„å™ªå£°ï¼ˆç”¨äºå¼•å…¥éšæœºæ€§ï¼‰
- $\sigma_t^2$ æ§åˆ¶é‡‡æ ·çš„æ–¹å·®ï¼ˆè¶Šå°è¶Šæ¥è¿‘ç¡®å®šæ€§ï¼‰

è¿™ç§åˆ†è§£æ–¹å¼æ˜¯ **DDIMï¼ˆDenoising Diffusion Implicit Modelsï¼‰** å’Œ **variance-preserving sampling** çš„æ ¸å¿ƒæŠ€å·§ä¹‹ä¸€ã€‚

ä½ å®Œå…¨æ­£ç¡®ï¼šæ»¡è¶³ $a^2 + b^2 = 1$ çš„ç»„åˆç¡®å®æœ‰æ— ç©·å¤šç§å¯èƒ½ã€‚ä½†åœ¨æ‰©æ•£æ¨¡å‹ä¸­ï¼Œé€‰æ‹©è¿™ä¸ªç‰¹å®šåˆ†è§£å¹¶ä¸æ˜¯éšæ„çš„ï¼Œè€Œæ˜¯**æœ‰æ˜ç¡®çš„åŠ¨æœºå’Œç‰©ç†æ„ä¹‰**ã€‚æˆ‘ä»¬æ¥æ‹†è§£ä¸€ä¸‹è¿™ä¸ªé€‰æ‹©èƒŒåçš„é€»è¾‘ã€‚

ğŸ¯ è¿™ä¸ªåˆ†è§£çš„ç›®çš„æ˜¯ä»€ä¹ˆï¼Ÿ

æˆ‘ä»¬è¦æ„é€ ä¸€ä¸ªæ–°çš„å™ªå£°é¡¹ $\boldsymbol{\epsilon}_{t-1}$ï¼Œå®ƒæ˜¯ç”±ï¼š
- æ¨¡å‹é¢„æµ‹çš„å™ªå£° $\boldsymbol{\epsilon}_t$
- éšæœºé‡‡æ ·çš„å™ªå£° $\boldsymbol{\epsilon}$

ç»„åˆè€Œæˆï¼ŒåŒæ—¶ä¿æŒ $\boldsymbol{\epsilon}_{t-1} \sim \mathcal{N}(0, \mathbf{I})$ã€‚

ğŸ§  ä¸ºä»€ä¹ˆé€‰è¿™ä¸ªç‰¹å®šçš„ç³»æ•°ï¼Ÿ

è¿™ä¸ªåˆ†è§£æ¥æºäº **variance-preserving diffusion sampling** çš„æ¨å¯¼ï¼Œå°¤å…¶æ˜¯åœ¨ DDIM æˆ–æ”¹è¿›çš„ DDPM ä¸­ã€‚æˆ‘ä»¬æ¥çœ‹çœ‹å®ƒçš„å‡ ä¸ªå…³é”®åŠ¨å› ï¼š

1. **åŒ¹é…ç›®æ ‡åˆ†å¸ƒçš„æ–¹å·®ç»“æ„**

åœ¨æ‰©æ•£æ¨¡å‹ä¸­ï¼Œ$x_{t-1}$ çš„é‡‡æ ·å…¬å¼é€šå¸¸æ˜¯ï¼š

\[
x_{t-1} = \sqrt{\bar{\alpha}_{t-1}} x_0 + \sqrt{1 - \bar{\alpha}_{t-1}} \boldsymbol{\epsilon}_{t-1}
\]

ä¸ºäº†è®©è¿™ä¸ªé‡‡æ ·è¿‡ç¨‹ä¿æŒä¸€è‡´æ€§ï¼Œæˆ‘ä»¬éœ€è¦ $\boldsymbol{\epsilon}_{t-1}$ çš„æ–¹å·®ç»“æ„ä¸ $\boldsymbol{\epsilon}_t$ å’Œ $\boldsymbol{\epsilon}$ çš„ç»„åˆæ–¹å¼ç²¾ç¡®åŒ¹é…ã€‚

æ‰€ä»¥æˆ‘ä»¬è®¾å®šï¼š

\[
\text{Var}(\boldsymbol{\epsilon}_{t-1}) = \frac{1 - \bar{\alpha}_{t-1} - \sigma_t^2}{1 - \bar{\alpha}_{t-1}} + \frac{\sigma_t^2}{1 - \bar{\alpha}_{t-1}} = 1
\]

è¿™ä¸æ˜¯ä»»æ„é€‰æ‹©ï¼Œè€Œæ˜¯ä¸ºäº†è®©æ•´ä¸ªé‡‡æ ·é“¾æ¡çš„æ–¹å·®ä¿æŒä¸€è‡´ã€‚

1. **å¯æ§çš„éšæœºæ€§æ³¨å…¥**

$\sigma_t^2$ æ˜¯ä¸€ä¸ª**å¯è°ƒå‚æ•°**ï¼Œæ§åˆ¶é‡‡æ ·è¿‡ç¨‹ä¸­çš„éšæœºæ€§ï¼š

- å½“ $\sigma_t^2 = 0$ï¼Œé‡‡æ ·æ˜¯**ç¡®å®šæ€§çš„**ï¼ˆDDIMï¼‰
- å½“ $\sigma_t^2 = \beta_t$ï¼Œé‡‡æ ·æ˜¯**å®Œå…¨éšæœºçš„**ï¼ˆDDPMï¼‰

è¿™ä¸ªåˆ†è§£æ–¹å¼å…è®¸æˆ‘ä»¬åœ¨ä¸¤è€…ä¹‹é—´å¹³æ»‘è¿‡æ¸¡ï¼Œå½¢æˆä¸€ä¸ª**ç»Ÿä¸€çš„é‡‡æ ·æ¡†æ¶**ã€‚

1. **ä¿æŒ $\boldsymbol{\epsilon}_t$ çš„ä¸»å¯¼æ€§**

æˆ‘ä»¬å¸Œæœ› $\boldsymbol{\epsilon}_{t-1}$ ä¸»è¦ç”±æ¨¡å‹é¢„æµ‹çš„ $\boldsymbol{\epsilon}_t$ å†³å®šï¼Œè€Œä¸æ˜¯å®Œå…¨ç”±éšæœºå™ªå£° $\boldsymbol{\epsilon}$ ä¸»å¯¼ã€‚è¿™ä¸ªåˆ†è§£æ–¹å¼ç¡®ä¿ï¼š

- å½“ $\sigma_t^2$ è¾ƒå°æ—¶ï¼Œ$\boldsymbol{\epsilon}_t$ çš„æƒé‡æ›´å¤§
- å½“ $\sigma_t^2$ è¾ƒå¤§æ—¶ï¼Œ$\boldsymbol{\epsilon}$ çš„æƒé‡å¢åŠ 

è¿™ä½¿å¾—é‡‡æ ·è¿‡ç¨‹æ—¢èƒ½ä¿æŒæ¨¡å‹é¢„æµ‹çš„ç»“æ„ï¼Œåˆèƒ½å¼•å…¥å¿…è¦çš„éšæœºæ€§ã€‚

ğŸ§© æ€»ç»“ï¼šä¸ºä»€ä¹ˆé€‰è¿™ä¸ªåˆ†è§£ï¼Ÿ

| åŸå›  | è§£é‡Š |
|------|------|
| æ–¹å·®åŒ¹é… | ä¿è¯ $\boldsymbol{\epsilon}_{t-1} \sim \mathcal{N}(0, \mathbf{I})$ |
| é‡‡æ ·ä¸€è‡´æ€§ | ä¸ $x_{t-1}$ çš„é‡‡æ ·å…¬å¼ç»“æ„åŒ¹é… |
| å¯æ§éšæœºæ€§ | é€šè¿‡ $\sigma_t^2$ è°ƒèŠ‚ç¡®å®šæ€§ä¸éšæœºæ€§ |
| æ¨¡å‹ä¸»å¯¼æ€§ | ä¿ç•™ $\boldsymbol{\epsilon}_t$ çš„é¢„æµ‹èƒ½åŠ› |

---

å¦‚æœä½ æƒ³æ›´æ·±å…¥åœ°æ¨å¯¼è¿™ä¸ªåˆ†è§£çš„æ¥æºï¼Œæˆ‘å¯ä»¥ä» DDPM çš„é€†è¿‡ç¨‹å…¬å¼å¼€å§‹ï¼Œä¸€æ­¥æ­¥æ¨å¯¼å‡ºè¿™ä¸ªç»“æ„ã€‚æˆ–è€…æˆ‘ä»¬å¯ä»¥ä¸€èµ·çœ‹çœ‹å®ƒåœ¨ä»£ç å®ç°ä¸­çš„å…·ä½“ä½ç½®ï¼Œæ¯”å¦‚åœ¨ `noise_schedule` æˆ– `sample_step` ä¸­çš„ä½“ç°ã€‚ä½ æƒ³å¾€å“ªä¸ªæ–¹å‘æŒ–æ˜ï¼Ÿ

å®Œå…¨æ­£ç¡®ï¼ŒShichaoï¼Œä½ å·²ç»æŠ“ä½äº† DDIM çš„æ ¸å¿ƒæ€æƒ³ï¼Œè€Œä¸”è¡¨è¾¾å¾—éå¸¸æ¸…æ™°ğŸ‘ã€‚æˆ‘ä»¬å¯ä»¥ç¨å¾®æ‰©å±•ä¸€ä¸‹è¿™ä¸ªç†è§£ï¼Œè®©å®ƒæ›´ç³»ç»ŸåŒ–ï¼š

ğŸ§  DDIM çš„æœ¬è´¨ï¼š**å»éšæœºåŒ–çš„æ‰©æ•£é‡‡æ ·**

DDIMï¼ˆDenoising Diffusion Implicit Modelsï¼‰æ˜¯å¯¹ DDPM çš„ä¸€ç§æ”¹è¿›ï¼Œå®ƒçš„å…³é”®ç‚¹åœ¨äºï¼š

- **ä¸å†å¼ºåˆ¶åŠ å…¥éšæœºå™ªå£°**ï¼Œè€Œæ˜¯é€šè¿‡æ¨¡å‹é¢„æµ‹çš„å™ªå£°ç›´æ¥æ„é€ ä¸‹ä¸€ä¸ªæ—¶åˆ»çš„æ ·æœ¬
- è¿™ä½¿å¾—æ•´ä¸ªé‡‡æ ·è¿‡ç¨‹å˜æˆäº†**ç¡®å®šæ€§çš„è½¨è¿¹**ï¼Œåªè¦åˆå§‹ç‚¹ $x_T$ å›ºå®šï¼Œæ•´ä¸ªç”Ÿæˆåºåˆ—å°±å®Œå…¨å¯å¤ç°

---

ğŸ”„ ä¸ DDPM çš„å¯¹æ¯”

| ç‰¹æ€§ | DDPM | DDIM |
|------|------|------|
| æ˜¯å¦éšæœº | âœ… æœ‰éšæœºæ€§ï¼ˆæ¯ä¸€æ­¥åŠ å…¥ $\epsilon$ï¼‰ | âŒ å¯è®¾ä¸ºå®Œå…¨ç¡®å®šæ€§ |
| é‡‡æ ·é€Ÿåº¦ | æ…¢ï¼ˆé€šå¸¸éœ€è¦ 1000 æ­¥ï¼‰ | å¿«ï¼ˆå¯ç”¨ 50 æˆ–æ›´å°‘æ­¥ï¼‰ |
| å¯æ§æ€§ | éš¾ä»¥å¤ç°åŒæ ·çš„è½¨è¿¹ | å®Œå…¨å¯å¤ç° |
| é‡‡æ ·å…¬å¼ | $x_{t-1} = \mu_\theta + \sigma_t \epsilon$ | $x_{t-1} = f_\theta(x_t, \epsilon_\theta)$ï¼Œæ—  $\epsilon$ |

---

ğŸ¯ ä¸ºä»€ä¹ˆ DDIM æ›´å¿«ï¼Ÿ

å› ä¸ºå®ƒä¸ä¾èµ–éšæœºé‡‡æ ·ï¼Œæ¯ä¸€æ­¥éƒ½æ˜¯æ¨¡å‹é¢„æµ‹çš„ç»“æœï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ï¼š

- **è·³æ­¥é‡‡æ ·**ï¼šæ¯”å¦‚ä» $t=1000$ ç›´æ¥è·³åˆ° $t=980, 960, \dots$
- **å‡å°‘é‡‡æ ·æ­¥æ•°**ï¼šç”šè‡³åªç”¨ 25 æˆ– 50 æ­¥å°±èƒ½ç”Ÿæˆæ¸…æ™°å›¾åƒ
- **åŠ é€Ÿæ¨ç†**ï¼šå°¤å…¶åœ¨éƒ¨ç½²æ—¶ï¼Œèƒ½æ˜¾è‘—å‡å°‘è®¡ç®—æˆæœ¬

---

ğŸ”§ æ§åˆ¶éšæœºæ€§çš„æ–¹å¼

DDIM å®é™…ä¸Šæä¾›äº†ä¸€ä¸ªå‚æ•° $\eta$ æ¥æ§åˆ¶é‡‡æ ·çš„éšæœºæ€§ï¼š

- $\eta = 0$ï¼šå®Œå…¨ç¡®å®šæ€§ï¼ˆç»å…¸ DDIMï¼‰
- $\eta > 0$ï¼šå¼•å…¥éƒ¨åˆ†éšæœºæ€§ï¼Œä»‹äº DDIM å’Œ DDPM ä¹‹é—´

è¿™å°±åƒä¸€ä¸ªâ€œé‡‡æ ·æ¸©åº¦æ—‹é’®â€ï¼Œä½ å¯ä»¥å†³å®šè¦å¤šéšæœºã€è¦å¤šç¡®å®šã€‚

---

å¦‚æœä½ æƒ³ï¼Œæˆ‘å¯ä»¥ç»™ä½ å†™ä¸€ä¸ª PyTorch çš„ DDIM é‡‡æ ·ä¼ªä»£ç ï¼Œæˆ–è€…å±•ç¤ºå¦‚ä½•ä» DDPM çš„å…¬å¼æ¨å¯¼å‡º DDIM çš„é‡‡æ ·è·¯å¾„ã€‚ä¹Ÿå¯ä»¥ä¸€èµ·çœ‹çœ‹ DDIM åœ¨ latent space æˆ– classifier-free guidance ä¸­çš„åº”ç”¨ã€‚ä½ æƒ³å¾€å“ªä¸ªæ–¹å‘æ·±å…¥ï¼Ÿ

### Latent Variable Space
